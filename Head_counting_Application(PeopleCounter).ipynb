{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project on Calculating the Head Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np \n",
    "import cv2\n",
    "import imutils\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will decide whether the person is going IN or going OUT\n",
    "#It will return 2 elements, first the element itself and second its occurrances\n",
    "def find_majority_element(lst):\n",
    "    Map={}          #declare map for storing values of lst\n",
    "    maximum=('',0)   #(occurring element, occurrences)\n",
    "    for i in lst:\n",
    "        if i in Map:\n",
    "            Map[i]+=1      #Increment the value of element in Map if it is encountered more than once\n",
    "        else:\n",
    "            Map[i]=1        #When the element is encountered at first\n",
    "        #Keep track of maximum occurring element    \n",
    "        if Map[i]>maximum[1]:\n",
    "            maximum=(i,Map[i])\n",
    "    return maximum        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Started\n"
     ]
    }
   ],
   "source": [
    "count1=0 #When the person enters in the room (IN) (i.e;Total persons IN)\n",
    "count2=0 #When the element goes out of the room (OUT) (i.e; Total perons OUT)\n",
    "\n",
    "avgFrame=None   #This variable stores the first frame in grascale of the video\n",
    "\n",
    "xvalues=list()  #TO store values of X-coordinates of a person moving in Video\n",
    "                #1.If the person is moving from left to right(IN) the xvalues would be like (100,120,150,200,240,350,400)\n",
    "                #2.If the person is moving from right to left(OUT) the xvalues would be like (400,360,340,330,300,250,200,150)\n",
    "\n",
    "    \n",
    "motion=list()       #This can only stores the value 0 or 1 based on  xvalues(as defined above)\n",
    "                    #Later in the code we'll see how values in this tuple is filled\n",
    "                \n",
    "                \n",
    "\n",
    "#Creating the object of VideoCapture to read the different frames from the Video\n",
    "#We'll be passing the path of Video file in itsparameter\n",
    "#We can also Pass 0 as its parameter in this case Builtin camera of the system will get opened and will capture the first frame\n",
    "video=cv2.VideoCapture(\"myvideo.mp4\")\n",
    "\n",
    "#Since the Video is combination of large number of Frames\n",
    "#Now we'll be iterating over each frames\n",
    "while True:\n",
    "    \n",
    "    #This will add the window and start reading the frame. It will  return 2 things.\n",
    "    #1. check->bool type True if object(video) is able to read the frame\n",
    "    #2. frame->numpy array that represents the first image that video captures\n",
    "    check,frame=video.read()\n",
    "    \n",
    "    flag=True   #To indicate whether the person is in the frame (True menas no person is in the frame)\n",
    "\n",
    "    #When our Video is over the check will return false\n",
    "    if(check==False):\n",
    "        break\n",
    "    \n",
    "    #Image Preprocessing\n",
    "    #1. First we'll resize our frame because larger image reqiures more processing time\n",
    "    #2. Second We'll Convert the Coloured frame to gray Scale image and store it in variable gray\n",
    "    #3. Then further we will blur that grau image so as to reduce the noise \n",
    "    frame=imutils.resize(frame,width=500)\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray=cv2.GaussianBlur(gray,(21,21),0)\n",
    "    \n",
    "    \n",
    "    #The following if statement will run only once and will initialize the first frame\n",
    "    #This first frame is stored in variable->avgFrame\n",
    "    if avgFrame is None:\n",
    "        print(\"Model Started\")\n",
    "        avgFrame=gray.copy().astype(\"float\") #storing a copy of grayscale image in avgFrame\n",
    "        continue     #due to this 'continue' from here first iteration is skipped(Remember First frame is already stored)\n",
    "        \n",
    "        \n",
    "    \n",
    "    #Now, in Second itertation we accumulate the weighted average between the current frame and first frame\n",
    "    #Then we compute the difference between the current(Running) frame and First Frame\n",
    "    cv2.accumulateWeighted(gray,avgFrame,0.5)\n",
    "    frameDelta=cv2.absdiff(gray,cv2.convertScaleAbs(avgFrame))\n",
    "    \n",
    "    \n",
    "    #Now we'll be forming the threshold image with the help of frameDelta calculated above.\n",
    "    #This Threshold image is formed so that we can find the \"countours\" in the Frame.\n",
    "    thresh=cv2.threshold(frameDelta,5,255,cv2.THRESH_BINARY)[1] #cv2.THRESH_BINARY is a method of thresholding\n",
    "    thresh=cv2.dilate(thresh,None,iterations=2)     #We dilate the threshold image to fill the holes\n",
    "    \n",
    "    \n",
    "    #Now we'll find countours in this threshold image(A contour refers to the outline of an object)\n",
    "    #To find contours in an image, we need the OpenCV \"cv2.findContours\" function\n",
    "    #It Accepts 3 parameters-\n",
    "      #1.Copy of threshold image(Because this function is distructive in nature so we pass the copy)\n",
    "      #2.cv2.RETR_EXTERNAL tells OpenCV to compute the hierarchy (relationship) between contours  \n",
    "      #3.We tell OpenCV to compress the contours to save space using cv2.CV_CHAIN_APPROX_SIMPLE.\n",
    "    (cnts,_)=cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    #Now iterating over countours\n",
    "    for c in cnts:\n",
    "        #If the countour is too small the ignore it\n",
    "        if cv2.contourArea(c)<5000:\n",
    "            continue\n",
    "        #make the bounding rectangle if see the person(countours)   \n",
    "        #After that, store the x coordinate of the person moving in the frame\n",
    "        (x,y,w,h)=cv2.boundingRect(c)\n",
    "        xvalues.append(x)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        flag=False #It means that person is still in the frame\n",
    "                   #Count is only made when the person goes out of the frame this can be seen in below code.\n",
    "        \n",
    "    \n",
    "    #Calculating the length of list consisting of  X-coordinates \n",
    "    no_x = len(xvalues)\n",
    "    \n",
    "    #With the help of below if statement we'll insert values on our motion list\n",
    "    if (no_x > 2):\n",
    "        #If the difference between last two values is greater than 0, it means the person is moving from left to right(IN).\n",
    "        #for example if xvalues->(100,120,150,200,240,350,400) then 400-350 >0 so persin is moving IN and we append 1 to motion.\n",
    "        difference = xvalues[no_x - 1] - xvalues[no_x - 2]\n",
    "        if(difference > 0):\n",
    "            motion.append(1)\n",
    "        else:\n",
    "            motion.append(0)\n",
    "        #Similarly,If the difference between last two values is less than 0, it means the person is moving from right to left(OUT).\n",
    "        #for example if xvalues->(400,360,340,330,300,250,200,150) then,150-200<0 so persin is moving OUT and we append 0 to motion   \n",
    "            \n",
    "            \n",
    "    #print(\"xlaues-->\",xvalues)\n",
    "    #print(\"motion-->\",motion)\n",
    "    \n",
    "    \n",
    "    #The below if condition will run if the person is out of the frame since flag is True\n",
    "    if flag is True:\n",
    "        if (no_x > 5):\n",
    "            #This function will return the majority element in the list.\n",
    "            #On the basis of this we determine whether the person is going IN or OUT.\n",
    "            val, times = find_majority_element(motion) #for definition see above\n",
    "            if val == 1 and times >= 15:  #Means person is coming IN\n",
    "                count1 += 1\n",
    "            else:\n",
    "                count2 += 1               #Means Person is going OUT\n",
    "        \n",
    "        #Reset the xvalues and motion to NULL\n",
    "        xvalues = list()\n",
    "        motion = list()\n",
    "        \n",
    "    #For drawing the straight line in the frame on appropriate place\n",
    "    cv2.line(frame,(260,0),(260,480),(0,0,255),2)\n",
    "    cv2.line(frame,(320,0),(320,480),(0,255,0),2)\n",
    "    \n",
    "    #Placing the text on the frame\n",
    "    cv2.putText(frame,\"IN: {}\".format(count1),(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),2)\n",
    "    cv2.putText(frame,\"OUT: {}\".format(count2),(10,40),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "    \n",
    "    #This will display the current date and time(implemented with the help of datetime library imported above).\n",
    "    cv2.putText(frame, datetime.datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n",
    "                    (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "    \n",
    "    #This statement will capture the frame and show it\n",
    "    #Since the frame are being read in a whine loop so it will appear like a video\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Gray\",gray)\n",
    "    cv2.imshow('FrameDelta',frameDelta)\n",
    "    \n",
    "    \n",
    "    #if we'll press key 'q' then it will break from while loop\n",
    "    key=cv2.waitKey(10) & 0xFF\n",
    "    if(key==ord('q')):\n",
    "        break\n",
    "        \n",
    "video.release()   #This will release the video file in few milliseconds\n",
    "cv2.destroyAllWindows() #This will Close any open window\n",
    "\n",
    "                          #####################################\n",
    "                                         #END#\n",
    "                         ######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
